<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Edouard Chappon</title> <meta name="author" content="Edouard Chappon"> <meta name="description" content="This project aims to deblur and denoise images, with a focus on the MNIST dataset. The methodology is based on the " unfolded forward backward approach developed as part of the master thesis project at ens lyon.> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favi.png?b71398e59abbbceb51d3383fe55afffb"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://chappone.github.io/blog/2023/mat/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="theme-red"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Edouard </span>Chappon</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Unfolded neural network for deblur and denoise</h1> <p class="post-meta">October 16, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/formatting"> <i class="fas fa-hashtag fa-sm"></i> formatting</a>   <a href="/blog/tag/math"> <i class="fas fa-hashtag fa-sm"></i> math</a>     ·   <a href="/blog/category/sample-posts"> <i class="fas fa-tag fa-sm"></i> sample-posts</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h2><u>Introduction</u></h2> <p>This project aims to deblur and denoise images, with a focus on the MNIST dataset. The methodology is based on the “Unfolded Forward Backward” approach, developed as part of <a href="https://chappone.github.io/ws/assets/pdf/circumstellar.pdf">my master’s thesis project</a> at ENS Lyon. The code to produce the results of this blog post is available on my <a href="https://github.com/ChapponE/img_deblur" rel="external nofollow noopener" target="_blank">github account</a>.</p> <h2><u>Data</u></h2> <p>I worked with the standard MNIST dataset imported from the Keras library, consisting of 70,000 images, each of size \(28 \times 28\) pixels. To normalize these images, I divided each pixel’s value by 255 to bring them into the range of 0 to 1. To degrade the quality of the handwritten digits, I applied a Gaussian blur with a kernel size of \(7 \times 7\) and a standard deviation of 0.5. Subsequently, I introduced Gaussian noise with a standard deviation of 0.25, resulting in pairs of original and degraded images, as displayed below. We measured the difference between the degraded and original images using the traditional PSNR metric.</p> <div style="text-align: center"><img src="/assets/img/sample.png" alt="A sample image" width="320"></div> <p>The main objective of this project is to create an estimator for the original image based on the degraded image. The quality of this estimator is assessed using the PSNR metric.</p> <h2><u>Model</u></h2> <p>\(\bullet\) I adopted the classical formalism of inverse problems:<br> The goal of solving an \(\textit{inverse problem}\) is to create an estimator, denoted as \(\boldsymbol{\widehat{x}} \in \mathbb{R}^{28^2}\), from a set of observed measurements, represented as the degraded images \(\boldsymbol{y} \in \mathbb{R}^{28^2}\). The objective is to create an estimator that is close to the ground truth data, the original image \(\boldsymbol{\bar{x}}\). In our case, we have \(\boldsymbol{y} = A\boldsymbol{\bar{x}} + \mathbf{\epsilon}, \text{ with } A \in \mathbb{R}^{28^2 \times 28^2} \text{ and } \mathbf{\epsilon} \sim \mathbb{N}(\mathbf{0}, \mathbf{\sigma^2 I})\). With \(A\) the gaussian blur and \(\mathbf{\epsilon}\) the gaussian noise.</p> <p>\(\bullet\) The estimator \(\boldsymbol{\widehat{x}}\) for \(\boldsymbol{\bar{x}}\) is typically obtained by solving a variational problem, defined as follows: \(\begin{align} \widehat{\boldsymbol{x}} \in \underset{\boldsymbol{x} \in \mathbb{R}^{28^2}}{\arg \min}\left[\frac{1}{2}||\boldsymbol{y}-A\boldsymbol{x}||_2^2+\mathcal{P}(\boldsymbol{x})\right] \end{align}\) Here, \(||\boldsymbol{y}-A\boldsymbol{x}||_2^2\) represents the data fidelity term, ensuring that the degraded solution \(A\boldsymbol{\widehat{x}}\) is close to the degraded signal \(\boldsymbol{y}\). Additionally, \(\mathcal{P}: \mathbb{R}^{28^2} \rightarrow \mathbb{R}\) is a prior term. For more details on variational problems, you can refer to my Master’s thesis.</p> <p>\(\bullet\) Choosing an appropriate prior term can be challenging. However, once a suitable prior term is chosen, it is possible to find the minimizer of equation (1) using proximal iterative methods like Forward-Backward:<br> <span><span style="font-weight: bold;">Forward-Backward algorithm:</span><br> <span style="font-weight: bold;">Assumption:</span> \(\zeta := |||A^*A|||_2&lt;2,\)<br> <span style="font-weight: bold;">Input:</span> \(\boldsymbol{y}\in \mathbb{R}^{28^2}\), step size \(\tau\in ]0,2\zeta^{-1}[,\)<br> \(x^0 = A^*y,\)<br> <span style="font-weight: bold;">For</span> \(n = 0, 1, 2, \ldots\):<br> \(\quad \quad \tilde{x}^{n}=x^n-\tau A^*(Ax^n - \boldsymbol{y})\);<br> \(\quad \quad x^{n+1} = \operatorname{prox}_{\tau \mathcal{R}}(\tilde{x}^{n})\);<br> <span style="font-weight: bold;">Output:</span> \(\lim\limits_{n\rightarrow\infty}{x^n} \in{\arg\min\limits_{x \in \mathbb{R}^{28^2}}}\left[\dfrac{1}{2}||\boldsymbol{y}-A\boldsymbol{x}||_2^2+\mathcal{P}(\boldsymbol{x})\right]\) </span></p> <ul> <li>Remark: Let \(h: \mathcal{H} \rightarrow \mathbb{R},\) \(\forall x \in \mathcal{H} \quad \operatorname{prox}_{\tau h}(x)=\underset{y \in \mathcal{H}}{\operatorname{argmin}} \frac{1}{2 \tau}\|x-y\|^{2}+h(y)\)</li> </ul> <p>\(\bullet\) To address the challenge of selecting a suitable prior term, the iterations of Forward-Backward can be unfolded to learn the prior through deep-learning frameworks. The first unfolded network was introduced in the paper <a href="https://icml.cc/Conferences/2010/papers/449.pdf" rel="external nofollow noopener" target="_blank"> Learning Fast Approximations of Sparse Coding </a> in 2010. To parameterize the unfolded network, I replaced the proximal operator of the prior with UNets, denoted as \(U_{\theta^k}\). To facilitate the learning process, I limited the number of iterations to 5. The algorithm is defined as follows:\(\\\)</p> <p><span><span style="font-weight: bold;">Unfolded Forward-Backward architecture network:</span><br> <span style="font-weight: bold;">Assumption:</span> \(\zeta:=|||A^*A|||_2 &lt; 2,\, {U_{\theta^k}}_{k\in[0;4]},\) UNets,<br> <span style="font-weight: bold;">Input:</span> \(\boldsymbol{y}\in \mathbb{R}^{28^2}\), step size \(\tau \in ]0,2\zeta^{-1}[,\)<br> \(x^0 = A^*y,\)<br> <span style="font-weight: bold;">For</span> \(n = 0, 1, 2, \ldots 4\):<br> \(\quad \quad \tilde{x}^{n}=x^n- \tau A^*(y - Ax^n);\)<br> \(\quad \quad x^{n+1} = U_{\theta^{n+1}}(\tilde{x}^{n})\);<br> <span style="font-weight: bold;">Output:</span> \(f_\theta(y)=x^5\) </span></p> <p>\(\bullet\) I trained the unfolded network using \(300\) of the \(70\,000\) images from the MNIST dataset. I reserved \(10\,000\) images for testing. It is possible to play with the number of iterations, which corresponds to the layers of our neural network, and the number of scales of the UNets, which determine the size of the UNets. I kept the number of layers fixed at 5 and the number of scales within the set \(\{2, 3, 4\}\).</p> <h2><u>Results</u></h2> <p>\(\bullet\) I minimized the cost function, which is defined as the mean squared error on the \(300\) training images: \(\sum\limits_{i \in [1,300]} \|\bar{x}_i - f_\theta(y)\|^2_2\).</p> <p>\(\bullet\) In the following plot, the training was performed for 50 epochs using the Adam algorithm. The red curve represents the PSNR calculated on the test set, and the blue curve represents the value of the loss function with respect to the number of epochs. Additionally, a table displaying the mean PSNR on the test set, the number of parameters, and the training time is provided.</p> <div style="text-align: center"><img src="/assets/img/curves_mnist.PNG" alt="A sample image" width="820"></div> <div style="text-align: center"><img src="/assets/img/table_MNIST.png" alt="A sample image" width="490"></div> <p>\(\bullet\) It is evident that there is no significant difference between the three settings. This can be attributed to the relatively low number of training epochs. In my thesis, it was observed that a higher number of parameters leads to better PSNR results. However, training for hundreds of epochs on my personal computer, which lacks a GPU, is time-consuming. Additionally, it’s noteworthy that the training time increases with a higher number of scales. <br> Here is an example of a reconstructed sample, demonstrating the quality of the results:</p> <div style="text-align: center"><img src="/assets/img/sample_mnist.png" alt="A sample image" width="820"></div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>